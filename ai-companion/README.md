# Meowstar AI Companion Service

å–µæ˜Ÿå®‡å®™ AI é™ªä¼´å® ç‰©æœåŠ¡ - åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½å® ç‰©å¯¹è¯ç³»ç»Ÿ

## æ¦‚è¿°

å–µæ˜Ÿå®‡å®™ AI é™ªä¼´å® ç‰©çš„åç«¯æœåŠ¡ï¼Œæä¾›ï¼š
- ğŸ¤– **LLM å¯¹è¯æœåŠ¡** - æ”¯æŒ OpenAI å’Œ Ollama (æœ¬åœ°æ¨¡å‹)
- ğŸ§  **è®°å¿†ç³»ç»Ÿ** - çŸ­æœŸè®°å¿† + å‘é‡åŒ–é•¿æœŸè®°å¿†
- ğŸ­ **ä¸ªæ€§åŒ– Prompt** - åŸºäºå® ç‰©æ€§æ ¼ç”Ÿæˆå¯¹è¯é£æ ¼
- ğŸ”— **é“¾ä¸ŠåŒæ­¥** - ä¸ Substrate é“¾åŒæ­¥å® ç‰©ä¿¡æ¯

## æŠ€æœ¯æ ˆ

- **æ¡†æ¶**: FastAPI
- **LLM**: OpenAI API / Ollama (Qwen, Llama)
- **å‘é‡æ•°æ®åº“**: Qdrant
- **Embedding**: BGE-M3
- **ç¼“å­˜**: Redis
- **æ•°æ®åº“**: PostgreSQL

## é¡¹ç›®ç»“æ„

```
ai-companion/
â”œâ”€â”€ pyproject.toml          # é¡¹ç›®é…ç½®
â”œâ”€â”€ .env.example            # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ README.md
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ main.py             # FastAPI åº”ç”¨å…¥å£
    â”œâ”€â”€ config.py           # é…ç½®ç®¡ç†
    â”œâ”€â”€ models.py           # æ•°æ®æ¨¡å‹
    â”œâ”€â”€ api/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ routes.py       # API è·¯ç”±
    â”œâ”€â”€ chat/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ service.py      # èŠå¤©æœåŠ¡
    â”œâ”€â”€ llm/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ base.py         # LLM åŸºç±»
    â”‚   â”œâ”€â”€ openai_provider.py
    â”‚   â”œâ”€â”€ ollama_provider.py
    â”‚   â””â”€â”€ router.py       # LLM è·¯ç”±
    â”œâ”€â”€ memory/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ embedding.py    # æ–‡æœ¬å‘é‡åŒ–
    â”‚   â”œâ”€â”€ vector_store.py # Qdrant å­˜å‚¨
    â”‚   â””â”€â”€ memory_manager.py
    â””â”€â”€ prompt/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ templates.py    # Prompt æ¨¡æ¿
        â””â”€â”€ personality.py  # æ€§æ ¼åŒ– Prompt
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd ai-companion
pip install -e .
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

```bash
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶
```

### 3. å¯åŠ¨ä¾èµ–æœåŠ¡

```bash
# Qdrant (å‘é‡æ•°æ®åº“)
docker run -p 6333:6333 qdrant/qdrant

# Ollama (æœ¬åœ° LLM)
ollama pull qwen2.5:7b
ollama serve
```

### 4. å¯åŠ¨æœåŠ¡

```bash
uvicorn src.main:app --reload --host 0.0.0.0 --port 8000
```

### 5. è®¿é—® API æ–‡æ¡£

æ‰“å¼€ http://localhost:8000/docs

## API æ¥å£

### èŠå¤©

```bash
# å‘é€æ¶ˆæ¯
POST /api/v1/chat
{
    "pet_id": 1,
    "user_id": "5GrwvaEF...",
    "message": "ä½ å¥½å‘€ï¼"
}

# æµå¼å“åº”
POST /api/v1/chat/stream

# è·å–é—®å€™è¯­
GET /api/v1/chat/greeting/{pet_id}?user_id=xxx

# æ¸…é™¤å¯¹è¯
POST /api/v1/chat/clear/{pet_id}?user_id=xxx
```

### è®°å¿†ç®¡ç†

```bash
# è·å–è®°å¿†
GET /api/v1/memory/{pet_id}?user_id=xxx

# æ·»åŠ è®°å¿†
POST /api/v1/memory/{pet_id}?user_id=xxx&content=xxx

# åˆ é™¤è®°å¿†
DELETE /api/v1/memory/{memory_id}

# æœç´¢è®°å¿†
POST /api/v1/memory/search/{pet_id}?user_id=xxx&query=xxx
```

### å® ç‰©åŒæ­¥

```bash
# åŒæ­¥é“¾ä¸Šå® ç‰©ä¿¡æ¯
POST /api/v1/pet/sync
{
    "pet_id": 1,
    "owner": "5GrwvaEF...",
    "name": "å°é»‘",
    "element": "fire",
    "rarity": "rare",
    "level": 10,
    "evolution_stage": 1,
    "personality": {
        "extroversion": 70,
        "warmth": 80,
        "humor": 60,
        "curiosity": 75,
        "responsibility": 50
    }
}
```

## é…ç½®è¯´æ˜

| ç¯å¢ƒå˜é‡ | è¯´æ˜ | é»˜è®¤å€¼ |
|----------|------|--------|
| `LLM_PROVIDER` | LLM æä¾›å•† | `ollama` |
| `OPENAI_API_KEY` | OpenAI API Key | - |
| `OLLAMA_MODEL` | Ollama æ¨¡å‹ | `qwen2.5:7b` |
| `EMBEDDING_MODEL` | Embedding æ¨¡å‹ | `BAAI/bge-m3` |
| `QDRANT_HOST` | Qdrant åœ°å€ | `localhost` |
| `MEMORY_RETRIEVAL_TOP_K` | æ£€ç´¢è®°å¿†æ•°é‡ | `5` |

## æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Frontend / App                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Server                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Chat API   â”‚  â”‚ Memory API  â”‚  â”‚  Sync API   â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚                   â”‚
          â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM Router    â”‚  â”‚ Memory Manager  â”‚  â”‚  Blockchain     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚   (Substrate)   â”‚
â”‚  â”‚  OpenAI   â”‚  â”‚  â”‚  â”‚ Embedding â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  Ollama   â”‚  â”‚  â”‚  â”‚  Qdrant   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Docker éƒ¨ç½²

### å¿«é€Ÿå¯åŠ¨ (æ¨è)

```bash
# ä¸€é”®å¯åŠ¨ (è‡ªåŠ¨æ£€æµ‹ GPU)
./scripts/start.sh

# åœæ­¢æœåŠ¡
./scripts/stop.sh
```

### æ‰‹åŠ¨å¯åŠ¨

```bash
# GPU ç‰ˆæœ¬ (éœ€è¦ NVIDIA GPU)
docker compose up -d

# CPU ç‰ˆæœ¬ (æ—  GPU)
docker compose -f docker-compose.cpu.yml up -d
```

### æœåŠ¡ç«¯å£

| æœåŠ¡ | ç«¯å£ | è¯´æ˜ |
|------|------|------|
| AI Companion API | 8000 | ä¸»æœåŠ¡ |
| Ollama | 11434 | æœ¬åœ° LLM |
| Qdrant | 6333 | å‘é‡æ•°æ®åº“ |
| Redis | 6379 | ç¼“å­˜ |

### å¼€å‘æ¨¡å¼

```bash
# æœ¬åœ°å¼€å‘ (çƒ­é‡è½½)
./scripts/dev.sh
```

## å¼€å‘è®¡åˆ’

- [x] LLM å¯¹è¯æœåŠ¡
- [x] è®°å¿†å‘é‡åŒ–ç³»ç»Ÿ
- [x] ä¸ªæ€§åŒ– Prompt ç³»ç»Ÿ
- [x] Docker éƒ¨ç½²é…ç½®
- [ ] é“¾ä¸Šå® ç‰©ä¿¡æ¯åŒæ­¥
- [ ] LoRA å¾®è°ƒæ”¯æŒ
- [ ] æƒ…æ„Ÿåˆ†æå¢å¼º
- [ ] å¤šæ¨¡æ€æ”¯æŒ (è¯­éŸ³/å›¾ç‰‡)

---

*ç‰ˆæœ¬: v0.2.0*
*æ›´æ–°: 2026-01-30*
